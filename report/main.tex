\documentclass[runningheads]{llncs}
\usepackage[utf8]{inputenc}
\usepackage{setspace}
\usepackage{amssymb}
\usepackage{subfiles}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage[table,xcdraw]{xcolor}
\usepackage{longtable}
\usepackage[
backend=biber,
style=alphabetic,
giveninits=true
]{biblatex}
\DeclareNameAlias{default}{family-given}
\addbibresource{sources.bib}

\newcommand{\GCP}{{Graph Coloring Problem}\ }

\title{Surveying Cooperative Approaches for the Graph Coloring Problem}
\author{Gabriel Perez
\and
Corey Roberts
\and
Javier Valenzuela
}
\date{\today}

\authorrunning{Perez and Valenzuela and Roberts}

\institute{ Department of Electrical and Computer Engineering\\
University of Texas at Austin,\\
Austin, TX 78712\\
 \email{\{gabriel\_ohseas\_perez, croberts22, javier.valenzuela\}@utexas.edu}}

\begin{document}

\def\IEEEQED{\mbox{\rule[0pt]{1.3ex}{1.3ex}}} % for a filled box
\newcommand{\ep}{\hspace*{\fill}~\IEEEQED}
\newenvironment{mproof}[1][Proof]{{\bf #1: }}{\ep\vspace{.1in}}

\maketitle
\doublespacing

\begin{abstract}
  The \GCP is an NP-Complete problem with a rich history of approximation algorithms and heuristics.
  In this paper, we explore a modification to cooperative local search approaches for the graph coloring problem.
\end{abstract}

\section{Introduction}
The \GCP and its variants are long existing problems with a very low barrier to understanding. Despite that, the class of problems are incredibly difficult problem to solve exactly. Applications of the class of problems include identifying whether a circuit board has a short circuit, solving Sudoku for any size grid, and problems of scheduling exams for university lecturers \cite{10.5555/2851123}.

In this paper, we explore the idea of algorithms with various hyper-parameters cooperating to determine whether we get improved lower bounds for the \GCP approximations.

\section{Definitions}

\subsection{Graph \& Graph Properties}

A graph, $G$, is defined as $G = (V, E)$ a set of $n$ vertices $V$ and $m$ edges $E$. For this class of problems, we have a function $c: V \mapsto \mathbb{N} $. This function is called the \emph{coloring function}. The coloring is \emph{legal} if $\forall (u, v) \in E \implies c(u) \ne c(v)$. If the graph can be colored by using $k$ colors, then the graph is called $k-colorable$. The minimum $k$ that can be used to color the graph $G$ is called the \emph{chromatic number} of the graph $G$ denoted $\chi$. Another important term is neighboring coloring, which involves changing the color of a single vertex.

\subsection{Central Algorithm}

The central algorithm at the heart of these heuristics is to start at $|V|$ colorings, see if a feasible one exists, and then proceed downward.
This approach was used for all of the algorithms discussed in this paper. Appendix B describes additional starting coloring schemes considered for the algorithms, but ultimately not used.. Another key idea put into practice is the \emph{portfolio} approach, in which algorithms are seeded with a combination of hyper-parameters across the different threads and consequently reduce the current coloring size faster.

\subsection{Sharing Information}
Throughout this paper, there are references to the term sharing information. It is important to discuss what that precisely means. In this context, it represents the ability for algorithm threads to share what the lowest $k$ determined so far is. In addition, they are capable of sharing information about what moves they have made. This idea takes the form of a statistic matrix, as suggested by Li \cite{https://doi.org/10.5445/ir/1000083192}. It was implemented for PartialCol algorithm and Tabucol algorithm. It was not performed for the Metropolis algorithm. AntCol implements its own information sharing scheme via the pheromone trails.

\section{Existing Graph Coloring Problem Approaches }

In this section of the paper, we will reference some existing techniques and heuristics for graph coloring as they are vital to understanding the hypothesis.

\subsection{Tabucol \& PartialCol}\label{AA}
Tabucol is an algorithm proposed by Hertz and de Werra \cite{hdw}. The implementation here is the modified version by Galinier and Hao \cite{TabuCol} and discussed in the \emph{Guide to Graph Coloring} textbook \cite{10.5555/2851123}. The algorithm fundamentally revolves around moves, i.e., shifting a coloring to a neighboring coloring by only \emph{moving} the vertex causing the most conflicts to another color class. The algorithm attempts to prevent cyclic issues by making certain moves \emph{taboo}, hence the name. The rate at which moves become accessible again is dependent upon algorithm parameters. Another algorithm that was used in this paper is called PartialCol. PartialCol itself is very similar to the tabu approaches, but organizes vertices that cannot be colored without conflict.

\subsection{Metropolis Algorithm}
The metropolis algorithm simple algorithm in which we select vertices at random, recolor them, analyze the impact of the coloring change using a cost (or potential) function $H$, which denotes how many forbidden edges exist with the current coloring. Color transitioning moves are approved or rejected the with a probability based on the cost of the move. This algorithm utilizes a temperature coefficient utilize to adapt the likelihood of bad moves to be accepted, in the effort of avoiding solutions to dwell on local minimums.

\subsection{Antcol}

Antcol is an algorithm that was proposed by Thompson and Dowsland \cite{ant_kj}. It is an algorithm that utilizes both global and local search operators inspired by how ants determine optimal paths between their colonies and food sources. Ants tend to wander around randomly until a food source is found, where they then leave a pheromone trail for other ants to pick up on. This is key to Antcol: the algorithm attempts to make a handful of individual solutions (i.e.``ants") made in a non-deterministic manner. Then, each individual solution contributes to a global ``trail" solution that subsequent ``ants" then use as better heuristics. If features identified in each solution lead to better solutions, subsequent ants will continue to use those features using a matrix analogous to an ant's pheromone trail. Over time, inadequate solutions will disappear with an evaporation rate, giving stronger features more prominence.

\section{Cooperative Extensions to the Graph Coloring Problem}

This paper is comprised of several experiments:

\begin{itemize}

  \item Assessing whether one sees improved lower bounds on $\chi$ by running concurrent metropolis algorithms sharing information.
  \item Assessing the performance improvements of of PartialCol and Tabucol sharing lower bounds and partial colorings in identifying lower $\chi$.
  \item Assessing cooperative Tabucol approaches with other algorithms - that is to say extending the results of Li's use of the statistic matrix. \cite{https://doi.org/10.5445/ir/1000083192} The statistic matrix in this scenario is just a means to feature moves that are made less frequently.
  \item Assessing Antcol and tuning hyperparameters in both non-cooperative and cooperative modes. Notably, tuning the evaporation rate and number of ants used to approximate a solution.
\end{itemize}

The source code is available in this project. It was written using a standard Java console application with Gradle for managing dependencies. The most important of those dependencies is JGraphT, an open source library for handling graphs. The graph format that was used is the popular DIMACS format. Graphs used in this project are listed in the appendix in Table \ref{tab:graphs}.

\subsection{Cooperative Metropolis Algorithm}

The first experiment was assessing whether results for the Metropolis algorithm could be improved using multiple threads running different parameters and sharing information about what the lowest $k$ currently available is. Results from this experiment are captured in the appendix in Figure \ref{fig:metr1}. Noticeable difference in the minimum coloring achievable can be observed. Still, this approach did not yield any significant advances over using different algorithms such as Tabucol and PartialCol, whose results are discussed below.

\subsection{Cooperative Tabucol Algorithm}

The results in Figure \ref{fig:TabuColl} were intended to provide discussion with reference towards \cite{https://doi.org/10.5445/ir/1000083192}. It was found that the portfolio approach decreased the error on our optimal coloring determinations. However, the statistic matrix approach did not yield significant benefits (and appeared, in fact, detrimental). Possible explanations are listed in the PartialCol section.

\subsection{Cooperative PartialCol Algorithm}

The third experiment performed was analyzing the use of cooperative approaches and the statistic matrix for PartialCol. The results echoed those from Tabucol in that the statistic matrix did not provide any inherent benefit over the standard cooperative approaches or the multithreaded simple portfolio approach. The experiments performed showed a hinderance in performance instead. See the average error in Figure \ref{fig:partialcol}.
One possibility is that the implementation by Li had a different synchronization method. The implementation for this project was synchronized in access, but not in terms of iterations. The approach presented simply utilizes a portfolio approach to minimize the odds getting stuck in local minima, as the cooperative approach did not provide too much overhead.

\subsection{Antcol}

The final experiment performed was assessing Antcol and its hyperparameters: notably, if tuning the number of ants or the evaporation rate of the pheromone matrix would increase or decrease the optimal approximation. The average error for the hyperparameters that were included in \cite{10.5555/2851123} was approximately 0.18. This implementation included an evaporation rate of 0.75. When adjusting this to be higher or lower, we can see based on the graph in Figure \ref{fig:antcol} that lower values of evaporation tended to cater towards lower errors. Specifically, performance for smaller known-colorings proved to reach the optimal coloring. When we experimented using a shared dataset across multiple instances of Antcol, we noticed that the error increased in size. This is likely due to the somewhat random, sequential nature of how Antcol works. Because each individual contribution ends up contributing to the global matrix for each instance, it is possible that a solution set may differ than that of another. While the difference in average error is small, it's worth noting that both increasing the number of ants and lowering evaporation rates improved optimality at an expense in computational effort.

\section{Conclusion}
In this report we examined several different cooperative approaches to various local search algorithms. In addition, we leveraged the novel approach of Li and extended it to the PartialCol algorithm. For the evaluated graphs, no noticeable advantages were identified, and distinct disadvantages in terms of average error were observed instead. For all the algorithms, however, the portfolio approach seemed to provide improvements. Several other approaches were evaluated (for instance, a simple evolutionary algorithm), but it was found that they did not performed well enough to be viable).


\section{Appendix A. Graph Coloring Algorithms Evaluation Results}

The following list is the collection of graphs used to evaluate the algorithms described in this paper. ``Optimal is Approximate" denotes whether we know a lower bound for said graph.

\begin{longtable}{|l|l|l|l|l|}
  \hline
  \rowcolor[HTML]{F56B00}
  Optimal is Approximate & Optimal Coloring & Graph Name     & Vertices & Edges \\ \hline
  \endhead
%
  F          & 5                & dsjc125.1      & 125      & 736   \\ \hline
  F          & 17               & dsjc125.5      & 125      & 3891  \\ \hline
  F          & 44               & dsjc125.9      & 125      & 6961  \\ \hline
  F          & 8                & dsjc250.1      & 250      & 3218  \\ \hline
  T          & 28               & dsjc250.5      & 250      & 15668 \\ \hline
  F          & 72               & dsjc250.9      & 250      & 27897 \\ \hline
  F          & 26               & flat300\_26\_0 & 300      & 21633 \\ \hline
  F          & 28               & flat300\_28\_0 & 300      & 21695 \\ \hline
  F          & 10               & jean           & 80       & 254   \\ \hline
  F          & 15               & le450\_15b     & 450      & 8169  \\ \hline
  F          & 15               & le450\_15d     & 450      & 16750 \\ \hline
  F          & 5                & le450\_5a      & 450      & 5714  \\ \hline
  F          & 5                & le450\_5b      & 450      & 5734  \\ \hline
  F          & 20               & r1000.1        & 1000     & 14378 \\ \hline
  F          & 5                & r125.1         & 125      & 209   \\ \hline
  F          & 36               & r125.5         & 125      & 3838  \\ \hline
  F          & 8                & r250.1         & 250      & 867   \\ \hline
  F          & 64               & r250.1c        & 250      & 30227 \\ \hline
  T          & 28               & r250.5         & 250      & 14849 \\ \hline
  F          & 14               & school1\_nsh   & 352      & 14612 \\ \hline
  F          & 14               & school1        & 385      & 19095 \\ \hline
\caption{\label{tab:graphs}Collection of graphs used in the project.}
\end{longtable}

Note that multithreaded experiments were run with 8 threads. The notation $a[x,y]$ means that parameter $a$ was chosen with arbitrary values between $x$ and $y$. In lieu of $\alpha$ and $\beta$, a and b were used.

Figures \ref{fig:metr1} through \ref{fig:antcol} show accuracy performance for the different algorithms evaluated.

\begin{figure}[!h]
  \centering
  \includegraphics[width=1.125\textwidth]{Metropolis.png}
  \caption{Metropolis Results}
  \label{fig:metr1}
\end{figure}

\begin{figure}[!h]
  \centering
  \includegraphics[width=1\textwidth]{Tabucol.png}
  \caption{Tabucol Results}
  \label{fig:TabuColl}
\end{figure}

\begin{figure}[!h]
  \centering
  \includegraphics[width=1\textwidth]{PartialCol.png}
  \caption{PartialCol Results}
  \label{fig:partialcol}
\end{figure}

\begin{figure}[!h]
  \centering
  \includegraphics[width=1\textwidth]{AntCol.png}
  \caption{AntCol Results}
  \label{fig:antcol}
\end{figure}

\clearpage
\section{Appendix B. Coloring Initialization Comparison}[h]
While reviewing literature for the experiments presented in this paper, it was observed that certain authors would use different initial values for their coloring. As a side experiment, a brief comparison was made between a few of the initialization options presented. The initialization schemes compared were denominated simple-ordered, random, and unassigned-neighbor strategies.
The simple-ordered strategy is the general case of the initialization presented in the Central Algorithm section. Vertex are assigned a coloring in an orderly fashion from 1 to $k$, and colors are cycled over until all vertex have a color. The random strategy is self-explanatory, each vertex gets assigned a color from 1 to $k$ randomly with a uniform distribution. The last strategy, unassigned-neighbor, tries to exploit lightly connected graphs, by initializing all vertices to an $uncolored$ state.
This strategy first assigns a root vertex to color 1 and then traverses the graph, coloring each uncolored vertex found with color 1 should it not share an edge with a vertex of that color. Once the traversal is completed, a vertex from the uncolored vertex set is colored with color 2, and a new traversal begins, comparing neighbors to new color as the metric for coloring vertices. This process is repeated for all $k$ colors. The scenario that some vertices are left uncolored after the strategy is completed is high, particularly on heavily connected graphs, and the remaining uncolored vertices will be assigned randomly.\\

For the comparison experiment, it was decided to use the Metropolis algorithm due to the simplicity of the implementation of the benchmark for a proof-of-concept test. Results are shown in \ref{fig:seeding}.


\begin{figure}[!h]
  \centering
  \includegraphics[width=1\textwidth]{Seeding_error.png}
  \caption{Average error for different graph initialization strategies}
  \label{fig:seeding}
\end{figure}

While results vary slightly, it was concluded that no one seeding strategy yielded significantly better results than the rest, so a single strategy was used for the evaluation of algorithms in the main portion of the project.


\clearpage

\printbibliography

\end{document}
